{
    "name": "root",
    "gauges": {
        "FTG_RayReward00.Policy.Entropy.mean": {
            "value": 0.217664897441864,
            "min": 0.21182161569595337,
            "max": 1.7248188257217407,
            "count": 100
        },
        "FTG_RayReward00.Policy.Entropy.sum": {
            "value": 10874.755859375,
            "min": 10596.7998046875,
            "max": 86290.9609375,
            "count": 100
        },
        "FTG_RayReward00.Environment.EpisodeLength.mean": {
            "value": 72.12262773722628,
            "min": 63.80544747081712,
            "max": 160.6569579288026,
            "count": 100
        },
        "FTG_RayReward00.Environment.EpisodeLength.sum": {
            "value": 49404.0,
            "min": 49077.0,
            "max": 49842.0,
            "count": 100
        },
        "FTG_RayReward00.Step.mean": {
            "value": 4999991.0,
            "min": 49965.0,
            "max": 4999991.0,
            "count": 100
        },
        "FTG_RayReward00.Step.sum": {
            "value": 4999991.0,
            "min": 49965.0,
            "max": 4999991.0,
            "count": 100
        },
        "FTG_RayReward00.Policy.ExtrinsicValueEstimate.mean": {
            "value": 77.3632583618164,
            "min": -12.375964164733887,
            "max": 78.96910858154297,
            "count": 100
        },
        "FTG_RayReward00.Policy.ExtrinsicValueEstimate.sum": {
            "value": 89277.203125,
            "min": -12425.4677734375,
            "max": 95710.5625,
            "count": 100
        },
        "FTG_RayReward00.Environment.CumulativeReward.mean": {
            "value": 118.75730994152046,
            "min": -65.88845654993514,
            "max": 120.39630118890356,
            "count": 100
        },
        "FTG_RayReward00.Environment.CumulativeReward.sum": {
            "value": 81230.0,
            "min": -50800.0,
            "max": 91140.0,
            "count": 100
        },
        "FTG_RayReward00.Policy.ExtrinsicReward.mean": {
            "value": 118.75730994152046,
            "min": -65.88845654993514,
            "max": 120.39630118890356,
            "count": 100
        },
        "FTG_RayReward00.Policy.ExtrinsicReward.sum": {
            "value": 81230.0,
            "min": -50800.0,
            "max": 91140.0,
            "count": 100
        },
        "FTG_RayReward00.Losses.PolicyLoss.mean": {
            "value": 0.022558428799190247,
            "min": 0.019735417487099765,
            "max": 0.02765333801022886,
            "count": 100
        },
        "FTG_RayReward00.Losses.PolicyLoss.sum": {
            "value": 0.09023371519676099,
            "min": 0.08435900253631795,
            "max": 0.13563712088701627,
            "count": 100
        },
        "FTG_RayReward00.Losses.ValueLoss.mean": {
            "value": 220.65822982788086,
            "min": 160.47640640258788,
            "max": 1013.4277656555175,
            "count": 100
        },
        "FTG_RayReward00.Losses.ValueLoss.sum": {
            "value": 882.6329193115234,
            "min": 802.3820320129394,
            "max": 4053.71106262207,
            "count": 100
        },
        "FTG_RayReward00.Policy.LearningRate.mean": {
            "value": 1.4852795049399999e-06,
            "min": 1.4852795049399999e-06,
            "max": 0.00029846199051267,
            "count": 100
        },
        "FTG_RayReward00.Policy.LearningRate.sum": {
            "value": 5.9411180197599995e-06,
            "min": 5.9411180197599995e-06,
            "max": 0.00147843834718722,
            "count": 100
        },
        "FTG_RayReward00.Policy.Epsilon.mean": {
            "value": 0.10049506000000001,
            "min": 0.10049506000000001,
            "max": 0.19948733000000002,
            "count": 100
        },
        "FTG_RayReward00.Policy.Epsilon.sum": {
            "value": 0.40198024000000004,
            "min": 0.40198024000000004,
            "max": 0.99281278,
            "count": 100
        },
        "FTG_RayReward00.Policy.Beta.mean": {
            "value": 3.4703493999999994e-05,
            "min": 3.4703493999999994e-05,
            "max": 0.004974417767,
            "count": 100
        },
        "FTG_RayReward00.Policy.Beta.sum": {
            "value": 0.00013881397599999998,
            "min": 0.00013881397599999998,
            "max": 0.024641357722000004,
            "count": 100
        },
        "FTG_RayReward00.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        },
        "FTG_RayReward00.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 100
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1740560512",
        "python_version": "3.8.1rc1 (tags/v3.8.1rc1:b00a2b5, Dec 10 2019, 01:13:53) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\Wilder Reach\\AppData\\Local\\Programs\\Python\\Python38\\Scripts\\mlagents-learn .\\hyperparameters\\configuration_ten_times.yaml --force",
        "mlagents_version": "0.29.0",
        "mlagents_envs_version": "0.29.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.7.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1740593867"
    },
    "total": 33355.662786299996,
    "count": 1,
    "self": 0.039755500001774635,
    "children": {
        "run_training.setup": {
            "total": 0.22464240000000002,
            "count": 1,
            "self": 0.22464240000000002
        },
        "TrainerController.start_learning": {
            "total": 33355.3983884,
            "count": 1,
            "self": 82.75151239671686,
            "children": {
                "TrainerController._reset_env": {
                    "total": 26.6275111,
                    "count": 1,
                    "self": 26.6275111
                },
                "TrainerController.advance": {
                    "total": 33245.94727720328,
                    "count": 5048793,
                    "self": 75.22162050240877,
                    "children": {
                        "env_step": {
                            "total": 31862.133930998545,
                            "count": 5048793,
                            "self": 26819.46454769261,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 4984.705255503188,
                                    "count": 5048793,
                                    "self": 197.86396790279105,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 4786.841287600397,
                                            "count": 5000013,
                                            "self": 1037.2606508003023,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 3749.5806368000945,
                                                    "count": 5000013,
                                                    "self": 3749.5806368000945
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 57.96412780274706,
                                    "count": 5048793,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 33183.52664830561,
                                            "count": 5048793,
                                            "is_parallel": true,
                                            "self": 10373.328527904912,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.005667100000000147,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.002306899999997114,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.003360200000003033,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.003360200000003033
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 22810.1924533007,
                                                    "count": 5048793,
                                                    "is_parallel": true,
                                                    "self": 329.0135439008991,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 312.03691600151865,
                                                            "count": 5048793,
                                                            "is_parallel": true,
                                                            "self": 312.03691600151865
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 21009.781062001053,
                                                            "count": 5048793,
                                                            "is_parallel": true,
                                                            "self": 21009.781062001053
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 1159.3609313972302,
                                                            "count": 5048793,
                                                            "is_parallel": true,
                                                            "self": 734.669054198004,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 424.69187719922616,
                                                                    "count": 10097586,
                                                                    "is_parallel": true,
                                                                    "self": 424.69187719922616
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1308.5917257023257,
                            "count": 5048793,
                            "self": 104.11988360172359,
                            "children": {
                                "process_trajectory": {
                                    "total": 299.8301710006111,
                                    "count": 5048793,
                                    "self": 299.6130086006072,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.21716240000387188,
                                            "count": 1,
                                            "self": 0.21716240000387188
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 904.641671099991,
                                    "count": 486,
                                    "self": 574.2062319001027,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 330.43543919988826,
                                            "count": 14580,
                                            "self": 330.43543919988826
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 8.999995770864189e-07,
                    "count": 1,
                    "self": 8.999995770864189e-07
                },
                "TrainerController._save_models": {
                    "total": 0.0720867999989423,
                    "count": 1,
                    "self": 0.02807059999759076,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.044016200001351535,
                            "count": 1,
                            "self": 0.044016200001351535
                        }
                    }
                }
            }
        }
    }
}